{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.ndimage\n",
    "\n",
    "from skimage.feature import hog\n",
    "#from skimage import data, color, exposure\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.externals import joblib\n",
    "from characters import characters\n",
    "from sklearn.decomposition import PCA\n",
    "from __future__ import print_function\n",
    "from skimage.feature import hog\n",
    "from numpy import linalg as LA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Shuffling data...\n",
      "Scaling Features...\n",
      "Splitting dataset...\n",
      "(8000, 1024)\n",
      "(8000, 1)\n",
      "type of x_test <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "############################# Pre-processing data ##############################\n",
    "\"\"\"output\n",
    "x_train=(10000,1024)\n",
    "y_train=(10000,1)\n",
    "x_test=(2000,1024)\n",
    "y_test=(2000,1)\n",
    "type of data ='numpy.ndarray'\n",
    "\"\"\"\n",
    "verbose = True\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_data():\n",
    "    if verbose:\n",
    "        print('Loading dataset...')\n",
    "    m = 92000\n",
    "    data = np.load('dataset/dataset.npz')\n",
    "\n",
    "    x_train = data['arr_0']\n",
    "    y_train = data['arr_1'].reshape(78200, 1)\n",
    "    x_test = data['arr_2']\n",
    "    y_test = data['arr_3'].reshape(m - 78200, 1)\n",
    "\n",
    "    X = np.vstack([x_train, x_test]).reshape(m, 1024)\n",
    "    Y = np.vstack([y_train, y_test]).reshape(m, 1)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    if verbose:\n",
    "        print('Shuffling data...')\n",
    "    from sklearn.utils import shuffle\n",
    "    X, Y = shuffle(X, Y)\n",
    "    return X, Y\n",
    "\n",
    "def plot(X, Y, n = 0):\n",
    "    print('The image is character: ', characters[Y[n][0] - 1])\n",
    "    plt.imshow(X[n, :].reshape(32, 32), cmap = 'Greys')\n",
    "    plt.show()\n",
    "\n",
    "def scale(X, factor = 255):\n",
    "    if verbose:\n",
    "        print('Scaling Features...')\n",
    "    return X*(1/255)\n",
    "\n",
    "def split(x, y, ratio = 0.2):\n",
    "    if verbose:\n",
    "        print('Splitting dataset...')\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    return train_test_split(x, y, test_size = ratio)\n",
    "\n",
    "def main():\n",
    "    X, Y = load_data()\n",
    "    X, Y = shuffle(X, Y)\n",
    "    X = scale(X)\n",
    "    x_train, x_test, y_train, y_test = split(X, Y)\n",
    "\n",
    "    m_train = y_train.shape[0]\n",
    "    m_test =y_test.shape[0]\n",
    "   # plot(X,Y,1)\n",
    "    \n",
    "\n",
    "    #print('\\nTotal Training Set size: ', m_train)\n",
    "    #print('Total Test Set size: ', m_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = main()\n",
    "img_rows, img_cols = 32,32\n",
    "#print(y_test)\n",
    "\n",
    "x_train = x_train_full[0:20000]\n",
    "y_train = y_train_full[0:20000] \n",
    "x_test = x_train_full[20000:28000]\n",
    "y_test = y_train_full[20000:28000] \n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"type of x_test\",type(x_test))\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18400, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final=np.zeros((len(y_test_full),3))\n",
    "y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73600, 128)\n",
      "(18400, 128)\n"
     ]
    }
   ],
   "source": [
    "############################## H O G on full dataset ################################\n",
    "\"\"\"\n",
    "retuns, \n",
    "x_train_hog(73600,128)\n",
    "x_test_hog(18400,128)\n",
    "\"\"\"\n",
    "x_train_hog=[]\n",
    "x_test_hog=[]\n",
    "for i in range(len(x_train_full)):\n",
    "    x_train_feat1 = hog(np.reshape(x_train_full[i],(32,32)), orientations=8, pixels_per_cell=(8,8),\n",
    "                        cells_per_block=(4, 4))\n",
    "    x_train_hog.append(x_train_feat1)\n",
    "\n",
    "for i in range(len(x_test_full)):\n",
    "    x_test_feat1 = hog(np.reshape(x_test_full[i],(32,32)), orientations=8, pixels_per_cell=(8,8),\n",
    "                        cells_per_block=(4, 4))\n",
    "    x_test_hog.append(x_test_feat1)\n",
    "    \n",
    "x_train_hog=np.asarray(x_train_hog) \n",
    "x_test_hog=np.asarray(x_test_hog)    \n",
    "print((x_train_hog).shape)\n",
    "print((x_test_hog).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635869565217391\n"
     ]
    }
   ],
   "source": [
    "################################## K N N on full dataset #######################################\n",
    "\"\"\"\n",
    "KNN is applied after reducing the dimention with PCA and HOG,\n",
    "for applying pca use \"x_train_pca\" and \"y_train_pca\". \n",
    "Test accuracy with PCA's dimention is 5.5%\n",
    "for applying HOG use \"x_train_feat\" and \"y_train_feat\"\n",
    "Test accuracy with HOG's dimention is 85.5%\n",
    "\"\"\"\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='braycurtis')\n",
    "knn.fit(x_train_hog, y_train_full)\n",
    "# get the model accuracy\n",
    "model_score = knn.score(x_test_hog, y_test_full)\n",
    "print(model_score)\n",
    "y_final[:,1]=knn.predict(x_test_hog)\n",
    "# 94.44% for n_neighbours=3\n",
    "# 96.35% for n_neighbour =5\n",
    "# save trained model\n",
    "#joblib.dump(knn, 'knn_model.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(knn, open('knn_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=3000,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################### Random Forest ############################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(0)\n",
    "\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto',\n",
    "             min_impurity_split=None,\n",
    "            min_samples_leaf=1, \n",
    "            min_weight_fraction_leaf=0.0,  n_jobs=-1,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False,\n",
    "                            max_leaf_nodes= 3000, min_impurity_decrease= 0.0, min_samples_split= 3, n_estimators=\n",
    "                             160)\n",
    "\n",
    "#clf.fit(x_train,y_train)      #on noraml image          \n",
    "#clf.fit(x_train_hog,y_train)       # on HOG output\n",
    "clf.fit(x_train_hog,y_train_full)   #on full dataset (hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.9248369565217391\n",
      "Train accuracy 0.9885326086956522\n"
     ]
    }
   ],
   "source": [
    "######################################### HOG on random forest full dataset #####################################\n",
    "y_pred=clf.predict(x_test_hog)\n",
    "sum1=0\n",
    "for i in range (len(y_test_full)):\n",
    "    if(y_test_full[i]==y_pred[i]):\n",
    "        sum1=sum1+1\n",
    "print('Test accuracy',sum1/len(y_test_full))\n",
    "\n",
    "y_pred_train=clf.predict(x_train_hog)\n",
    "sum1=0\n",
    "for i in range (len(y_train_full)):\n",
    "    if(y_train_full[i]==y_pred_train[i]):\n",
    "        sum1=sum1+1\n",
    "print('Train accuracy',sum1/len(y_train_full))\n",
    "\n",
    "y_final[:,0]=y_pred\n",
    "\n",
    "#88.8   1200\n",
    "#89.175  #1400\n",
    "#89.51   #1600\n",
    "#89.975   #1900\n",
    "#90.15      #2100  \n",
    "#90.95    #3000              on 20,000 traning example  and 1100 leaves\n",
    "#90.915   #2800\n",
    "\n",
    "#Test accuracy 0.9248369565217391     on 3000 leaves and 160 estimator on full dataset\n",
    "#Train accuracy 0.9885326086956522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('random_forest_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940054347826087\n"
     ]
    }
   ],
   "source": [
    "########################################## HOG + SVM #########################################################\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='linear',gamma=0.00001,C=90) #gamma is for rbf/polynomial kernal\n",
    "#model=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=50, multi_class='ovr', fit_intercept=True, intercept_scaling=10, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(x_train_hog, y_train_full)\n",
    "w=model.score(x_test_hog, y_test_full)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test_hog)\n",
    "print(w)\n",
    "y_final[:,2]=predicted\n",
    "#with C=1 in svm we got 69.79% accuracy\n",
    "#with C=90 in svm we got 94.07% accuracy (on full dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('hog_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "y_final[:,0]=random forest\n",
    "y_final[:,1]=knn\n",
    "y_final[:,2]=svm\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(y_final)\n",
    "a=df.mode(axis=1)\n",
    "y_mode=np.zeros((len(a),1))\n",
    "for i in range(len(a)):\n",
    "    y_mode[i]=a[0][i]\n",
    "#print(y_final)\n",
    "sum1=0\n",
    "print(\"y_final shape\",y_final.shape)\n",
    "print(\"y_mode shape\",y_mode.shape)\n",
    "print('Train accuracy'+str(np.sum(y_test_full==y_mode)/18400))\n",
    "\n",
    "\n",
    "\n",
    "# test accuracy 96.0815%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18400,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To load model\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "\n",
    "\"\"\"\n",
    "y_final[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_random_forest.txt', 'w') as f:\n",
    "    f.write(str(y_final[:,0]))  # Python 3.x\n",
    "\n",
    "with open('y_knn.txt', 'w') as f:\n",
    "    f.write(str(y_final[:,1]))  # Python 3.x\n",
    "\n",
    "with open('y_svm.txt', 'w') as f:\n",
    "    f.write(str(y_final[:,2]))  # Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
